{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02467 Assignment 2\n",
    "s204085 Cornelius Erichs & s204076 Natasha Hougaard\n",
    "\n",
    "#### GitHub repository\n",
    "Here is our repository on GitHub: https://github.com/natasha0301/Assigment2-CSS\n",
    "\n",
    "The commit history does not represent the true story of collaboration, as it was worked on by both of us at the sametime while sharing our screen on zoom, or looking over the other persons shoulder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Mixing Patterns and Assortativity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each node, compute the fraction of edges that connect to a node that works in the same top field. Find the average value across all nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5842856084183233\n"
     ]
    }
   ],
   "source": [
    "from networkx.readwrite import json_graph\n",
    "import networkx as nx\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def read_json_file(filename):\n",
    "    with open(filename) as f:\n",
    "        js_graph = json.load(f)\n",
    "    return json_graph.node_link_graph(js_graph)\n",
    "G = read_json_file(\"data_total.json\")\n",
    "\n",
    "def same_field(G):\n",
    "    same_field_fractions = []\n",
    "    for node in G.nodes():\n",
    "        same_field_neighbors = 0\n",
    "        total_neighbors = 0\n",
    "        \n",
    "        for neighbor in G.neighbors(node):\n",
    "            if G.nodes[neighbor][\"field\"] == G.nodes[node][\"field\"]:\n",
    "                same_field_neighbors += 1\n",
    "            total_neighbors += 1\n",
    "        \n",
    "        if total_neighbors > 0:\n",
    "            same_field_fraction = same_field_neighbors / total_neighbors\n",
    "        else:\n",
    "            same_field_fraction = 0\n",
    "        same_field_fractions.append(same_field_fraction)\n",
    "    return same_field_fractions\n",
    "\n",
    "same_field_fractions = same_field(G)\n",
    "print(np.mean(same_field(G)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new graph, with the same nodes and edges, but where the association between nodes and field is shuffled. Compute the measure above for this randomized graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18158584310381023\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "shuffled_G = G.copy()\n",
    "\n",
    "fields = [G.nodes[node][\"field\"] for node in G.nodes()]\n",
    "random.shuffle(fields)\n",
    "\n",
    "for i, node in enumerate(shuffled_G.nodes()):\n",
    "    shuffled_G.nodes[node][\"field\"] = fields[i]\n",
    "    \n",
    "print(np.mean(same_field(shuffled_G)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the point above 100 times (at least). Plot the distribution of the values obtained and compare it with the value you have found for the real graph. Is the chance to connect to a member of the same field significantly higher than it would be by chance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  3.,   9.,  28.,  78., 113., 113.,  90.,  50.,  12.,   4.]),\n",
       " array([0.17209527, 0.17330026, 0.17450525, 0.17571023, 0.17691522,\n",
       "        0.17812021, 0.17932519, 0.18053018, 0.18173517, 0.18294015,\n",
       "        0.18414514]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "results = []\n",
    "for i in range(500):\n",
    "    random.shuffle(fields)\n",
    "\n",
    "    for i, node in enumerate(shuffled_G.nodes()):\n",
    "        shuffled_G.nodes[node][\"field\"] = fields[i]\n",
    "    \n",
    "    results.append(np.mean(same_field(shuffled_G)))\n",
    "    \n",
    "plt.hist(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the assortativity coefficient with respect to author's field. How do you interpret the value you obtain? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Agricultural And Food Sciences' 'Art' 'Business' 'Chemistry'\n",
      " 'Computer Science' 'Economics' 'Education' 'Engineering'\n",
      " 'Environmental Science' 'Geography' 'Geology' 'History' 'Law'\n",
      " 'Linguistics' 'Materials Science' 'Mathematics' 'Medicine' 'Philosophy'\n",
      " 'Physics' 'Political Science' 'Psychology' 'Sociology' 'nan']\n",
      "0.7106920785154831\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(fields))\n",
    "unique_fields = {'Agricultural And Food Sciences' : 0,\n",
    "            'Art' : 1,\n",
    "            'Business' : 2,\n",
    "            'Chemistry' : 3,\n",
    "            'Computer Science' : 4,\n",
    "            'Economics' : 5,\n",
    "            'Education' : 6,\n",
    "            'Engineering' : 7,\n",
    "            'Environmental Science' : 8,\n",
    "            'Geography' : 9,\n",
    "            'Geology' : 10,\n",
    "            'History' : 11,\n",
    "            'Law' : 12,\n",
    "            'Linguistics': 13,\n",
    "            'Materials Science': 14,\n",
    "            'Mathematics': 15,\n",
    "            'Medicine': 16,\n",
    "            'Philosophy' : 17,\n",
    "            'Physics' : 18,\n",
    "            'Political Science' : 19,\n",
    "            'Psychology' : 20,\n",
    "            'Sociology' : 21,\n",
    "            None:22}\n",
    "\n",
    "matrix = np.zeros((len(unique_fields),len(unique_fields)))\n",
    "\n",
    "values = nx.get_node_attributes(G, \"field\").values()\n",
    "num_values = len(values)\n",
    "\n",
    "for start, end in G.edges(): # Looping over all edges in graph (since its undirected its not really start and stop)\n",
    "    x = G.nodes[start][\"field\"] # Getting the start point of the edge \n",
    "    y = G.nodes[end][\"field\"] # Getting the end point of the edge \n",
    "    if x in unique_fields: \n",
    "        x = unique_fields[x]\n",
    "    else:\n",
    "        x = unique_fields[None] # in case x is nan\n",
    "        \n",
    "    if y in unique_fields:\n",
    "        y = unique_fields[y]\n",
    "    else:\n",
    "        y = unique_fields[None] # in case y is nan\n",
    "    matrix[x, y] += 1 \n",
    "    \n",
    "num_edges = len(G.edges())\n",
    "matrix /= num_edges # averaging the occurence with the total edges\n",
    "\n",
    "trace = np.trace(matrix) # trace of the matrix, the sum of the diagonal entries\n",
    "mix_matrix = np.sum(np.matmul(matrix, matrix))\n",
    "\n",
    "r1 = (trace-mix_matrix)/(1-mix_matrix) # Eq. 2\n",
    "print(r1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of 0.71 indicated some clusters of nodes are formed based on their top field, but there are also occurences where this is not the case. With 0 indicating random mixing we can see that their field plays some kind of role."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the graph assortative with respect to the degree? (e.g. do high-degree scientists tend to link to other high-degree scientists, and low-degree scientists to other low-degree scientists?). Provide an interpretation of your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the assortativity coefficient is > 0, it suggests that nodes with similar degrees tend to be connected to each other, indicating assortative mixing w.r.t. the degree. And if the assortativity coefficient is < 0, it suggests that nodes with different degrees tend to be connected to each other, indicating disassortative mixing w.r.t. the degree. \n",
    "\n",
    "A value of 0.71 for the assortativity coefficient suggests that there is a degree of assortative mixing for the authors with respect to the their top fields. In other words, authors with the same top field are more likely to be connected to each other than to nodes with different top fields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Communities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE 2: ZACHARYS'S KARATE CLUB**\n",
    "\n",
    "In this exercise, we will work on Zarachy's karate club graph (refer to the Introduction of Chapter 9). The dataset is available in NetworkX, by calling the function karate_club_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Visualize the graph using netwulf. Set the color of each node based on the club split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from netwulf import visualize\n",
    "\n",
    "G = nx.karate_club_graph()\n",
    "\n",
    "#First we set the color of each node based on the club split\n",
    "colors = ['red' if G.nodes[n]['club'] == 'Mr. Hi' else 'blue' for n in G.nodes()]\n",
    "\n",
    "#Then we add the colors to the node attributes\n",
    "for i, n in enumerate(G.nodes()):\n",
    "    G.nodes[n]['color'] = colors[i]\n",
    "\n",
    "#Visualize the graph\n",
    "visualize(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Write a function to compute the modularity of a graph partitioning using equation 9.12 in the book: \n",
    "\n",
    "$M=\\sum_{c=1}^{n_c}\\left[\\frac{L_c}{L}-(\\frac{k_c}{2L})^2\\right]$ \n",
    "\n",
    "\n",
    "\n",
    "The function should take a networkX Graph and a partitioning as inputs and return the modularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def compute_modularity(G,partitioning):\n",
    "    L = G.number_of_edges()\n",
    "    M = 0\n",
    "    communities = set(partitioning.values())\n",
    "\n",
    "    for community in communities:\n",
    "        nodes_in_community = [node for node, community_id in partitioning.items() if community_id == community]\n",
    "        subgraph = G.subgraph(nodes_in_community)\n",
    "        k_c = sum(dict(subgraph.degree()).values())\n",
    "        L_c = subgraph.number_of_edges()\n",
    "        M += L_c / L - (k_c / (2 * L)) ** 2\n",
    "\n",
    "    return M\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Explain in your own words the concept of modularity **REFRASE**\n",
    "\n",
    "Modularity is a measure of the structure of a network, which is a collection of nodes (also known as vertices) and the edges (also known as links) that connect them. The concept of modularity is based on the idea that a well-connected network can be divided into groups of nodes, known as communities or clusters, where the nodes within each group are more densely connected to each other than to nodes outside the group.\n",
    "\n",
    "Modularity is a measure of how well a network can be divided into such communities. Specifically, modularity quantifies the difference between the number of edges within communities and the expected number of edges within communities if the edges were placed randomly, while preserving the degree distribution of the nodes. In other words, modularity measures the extent to which the edges in a network are concentrated within communities, rather than being distributed randomly throughout the network.\n",
    "\n",
    "Modularity is typically expressed as a number between -1 and 1. A high positive value of modularity indicates that the network is highly modular, with many densely connected communities, while a low or negative value indicates that the network is less modular, with communities that are not well-defined. The concept of modularity has many applications in network science, including community detection, network visualization, and network comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Compute the modularity of the Karate club split partitioning using the function you just wrote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def compute_modularity(G,partitioning):\n",
    "    L = G.number_of_edges()\n",
    "    M = 0\n",
    "    communities = set(partitioning.values())\n",
    "\n",
    "    for community in communities:\n",
    "        nodes_in_community = [node for node, community_id in partitioning.items() if community_id == community]\n",
    "        subgraph = G.subgraph(nodes_in_community)\n",
    "        k_c = sum(dict(subgraph.degree()).values())\n",
    "        L_c = subgraph.number_of_edges()\n",
    "        M += L_c / L - (k_c / (2 * L)) ** 2\n",
    "\n",
    "    return M\n",
    "\n",
    "#We start by loading the Karate club graph\n",
    "G = nx.karate_club_graph()\n",
    "\n",
    "#First we get the club split partitioning from the node attributes\n",
    "club_split = nx.get_node_attributes(G, \"club\")\n",
    "\n",
    "#Then we compute the modularity of the partitioning by using the function above\n",
    "modularity = compute_modularity(G, club_split)\n",
    "\n",
    "print(f\"The modularity of the Karate club split partitioning using the function is {modularity:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. We will now perform a small randomization experiment to assess if the modularity you just computed is statitically different from 0. To do so, we will implement the double edge swap algorithm. Given a network G, this algorithm creates a new network, such that each node has exactly the same degree as in the original network, but different connections. Here is how the algorithm works.\n",
    "\n",
    "    a. Create an identical copy of your original network.\n",
    "    \n",
    "    b. Consider two edges in your new network (u,v) and (x,y), such that u!=v and v!=x.\n",
    "    \n",
    "    c. If none of edges (u,y) and (x,v) exists already, add them to the network and remove edges (u,v) and (x,y).\n",
    "    \n",
    "Repeat steps b. and c. to achieve at least N swaps (I suggest N to be larger than the number of edges)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
